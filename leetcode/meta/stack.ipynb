{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "myStack = deque()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque(['a', 'b', 'c'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myStack.append('a')\n",
    "myStack.append('b')\n",
    "myStack.append('c')\n",
    "myStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myStack.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque(['a', 'b'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myStack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myStack2 = []\n",
    "myStack2.append('a')\n",
    "myStack2.append('b')\n",
    "myStack2.append('c')\n",
    "myStack2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myStack2.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myStack2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myStack2.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myStack2.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty\n"
     ]
    }
   ],
   "source": [
    "if myStack:\n",
    "    print(\"Not empty\")\n",
    "else:\n",
    "    print(\"empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "class RunningMedian:\n",
    "    def __init__(self):\n",
    "        self.max_heap = []  # to store the lower half of the numbers, max heap\n",
    "        self.min_heap = []  # to store the upper half of the numbers, min heap\n",
    "\n",
    "    def add_number(self, num):\n",
    "        # Add to max heap\n",
    "        if not self.max_heap or num < -self.max_heap[0]:\n",
    "            # We push negative numbers because Python's heap is a min-heap by default\n",
    "            heapq.heappush(self.max_heap, -num)\n",
    "        else:\n",
    "            heapq.heappush(self.min_heap, num)\n",
    "\n",
    "        # Balance heaps (the max heap can have at most one more element than min heap)\n",
    "        if len(self.max_heap) > len(self.min_heap) + 1:\n",
    "            heapq.heappush(self.min_heap, -heapq.heappop(self.max_heap))\n",
    "        elif len(self.min_heap) > len(self.max_heap):\n",
    "            heapq.heappush(self.max_heap, -heapq.heappop(self.min_heap))\n",
    "\n",
    "    def find_running_median(self):\n",
    "        if len(self.max_heap) == len(self.min_heap):\n",
    "            # If even, the median is the average of the roots of both heaps\n",
    "            return float(-self.max_heap[0] + self.min_heap[0]) / 2.0\n",
    "        # Otherwise, the median is the root of the max heap\n",
    "        return float(-self.max_heap[0])\n",
    "\n",
    "# Usage\n",
    "running_median = RunningMedian()\n",
    "\n",
    "# Simulating a stream of data\n",
    "stream_of_data = [5, 15, 1, 3, 8, 7, 9, 10, 6, 11]\n",
    "for num in stream_of_data:\n",
    "    running_median.add_number(num)\n",
    "    print(\"Current list:\", sorted(stream_of_data[:stream_of_data.index(num)+1]))  # Just to show progress\n",
    "    print(\"Running median:\", running_median.find_running_median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Centroids: [[0.31608979 0.79355926]\n",
      " [0.80202702 0.56167706]\n",
      " [0.27041205 0.26125571]]\n",
      "Cluster assignments: [0 1 2 0 0 0 2 1 2 1 2 1 0 0 0 2 0 1 1 2 1 1 0 0 1 2 1 0 1 0 2 0 0 0 2 1 0\n",
      " 1 1 2 0 2 2 2 2 1 0 1 1 0 2 0 2 1 1 2 1 2 0 0 2 2 1 0 1 2 1 2 1 0 1 0 2 2\n",
      " 1 1 0 1 2 2 2 0 2 1 1 1 1 0 1 2 0 0 0 1 0 1 0 0 2 0]\n"
     ]
    }
   ],
   "source": [
    "# Implement K-means from scratch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def kmeans(X, k, max_iterations=100, tolerance=1e-4):\n",
    "    \"\"\"\n",
    "    Implement k-means clustering algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    X (ndarray): Data points to cluster.\n",
    "    k (int): Number of clusters.\n",
    "    max_iterations (int): Maximum number of iterations.\n",
    "    tolerance (float): Minimal centroid update difference to declare convergence.\n",
    "\n",
    "    Returns:\n",
    "    ndarray: Final centroids' positions.\n",
    "    ndarray: An array indicating the cluster of each data point.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Initialize centroids randomly from the data points\n",
    "    centroids = X[np.random.choice(X.shape[0], k, replace=False), :]\n",
    "\n",
    "    for _ in range(max_iterations):\n",
    "        # Step 2: Assign each data point to the closest centroid\n",
    "        # Euclidean distances are calculated for each point with every centroid\n",
    "        distances = np.sqrt(((X - centroids[:, np.newaxis]) ** 2).sum(axis=2))\n",
    "        closest_centroids = np.argmin(distances, axis=0)\n",
    "\n",
    "        # Step 3: Recalculate centroids\n",
    "        new_centroids = np.array([X[closest_centroids == i].mean(axis=0) for i in range(k)])\n",
    "\n",
    "        # If centroids don't change much (convergence), break out of loop\n",
    "        if np.sqrt(((new_centroids - centroids) ** 2).sum()) < tolerance:\n",
    "            break\n",
    "\n",
    "        centroids = new_centroids\n",
    "\n",
    "    return centroids, closest_centroids\n",
    "\n",
    "# Usage:\n",
    "# Assume 'data' is a NumPy 2D array containing your data, each row is a data point\n",
    "# For example, we create 100 random 2D points (i.e., they have x and y coordinates)\n",
    "data = np.random.rand(100, 2)\n",
    "\n",
    "# Number of clusters\n",
    "k = 3\n",
    "\n",
    "# Perform k-means clustering\n",
    "final_centroids, assignments = kmeans(data, k)\n",
    "\n",
    "print(\"Final Centroids:\", final_centroids)\n",
    "print(\"Cluster assignments:\", assignments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why the clusters look more rectangular type? - the original data is not scaled\n",
    "\n",
    "# Early stopping criteria - how to implement it?\n",
    "# - error based, centroid based\n",
    "\n",
    "# what are the hyperparameters of k-means?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Clusters (k):\n",
    "\n",
    "This is the most critical hyperparameter. The entire goal of K-means is to separate data into 'k' clusters. However, the true number of clusters in the data is not always known in advance.\n",
    "Setting 'k' too low means you could be underfitting, and setting 'k' too high means you could be overfitting. Methods like the Elbow method, the Silhouette method, or the Davies-Bouldin index can help determine the optimal 'k'.\n",
    "Initialization Method:\n",
    "\n",
    "The initial placement of centroids is crucial, as poor placement can lead to suboptimal clusters. Methods like random initialization or k-means++ (which chooses initial centers so that they are statistically close to the final ones) are popular.\n",
    "Poor initialization can lead the algorithm to converge to a local minimum, which is one of the biggest problems in K-means.\n",
    "Distance Metric:\n",
    "\n",
    "Though the standard K-means algorithm uses the Euclidean distance, this is itself a hyperparameter. You might choose to use Manhattan, cosine, or other distance metrics, depending on the nature of your data.\n",
    "Different applications or types of data might demand different methods of assessing distance.\n",
    "Maximum Iterations:\n",
    "\n",
    "This parameter sets an upper limit on the number of iterations the algorithm is allowed to run. This is a safeguard against the possibility of the algorithm running indefinitely.\n",
    "While the algorithm generally converges quickly, the number of iterations can affect runtime. However, setting it too low may stop the algorithm before it has converged.\n",
    "Tolerance/Convergence Threshold:\n",
    "\n",
    "This parameter determines how much the centroids must move to consider the solution as having converged.\n",
    "A lower tolerance means that the algorithm will run until a finer convergence, which might be unnecessary and time-consuming.\n",
    "Algorithm / Variant of K-means:\n",
    "\n",
    "Besides standard K-means, there are other variants like Mini-Batch K-means, Bisecting K-means, etc., and choosing one of these is effectively choosing a set of hyperparameters (batch size, number of splits, etc.).\n",
    "Seed (Random State):\n",
    "\n",
    "The seed or random state for the random number generator is sometimes considered a hyperparameter, particularly because K-means (especially with random initialization) can produce different results with different seeds.\n",
    "Setting a seed (random state) allows for reproducibility of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmops-week1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
